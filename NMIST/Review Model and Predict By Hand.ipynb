{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is D4F8-2F03\n",
      "\n",
      " Directory of C:\\Users\\mattt_000\\Documents\\MachineLearning101\\MachineLearning101\\NMIST\\model\n",
      "\n",
      "18/08/2019  17:29    <DIR>          .\n",
      "18/08/2019  17:29    <DIR>          ..\n",
      "18/08/2019  11:08            78,480 20190818 110820.keras\n",
      "18/08/2019  11:21            78,480 20190818 112143.keras\n",
      "18/08/2019  17:29            78,480 20190818 172933.keras\n",
      "               3 File(s)        235,440 bytes\n",
      "               2 Dir(s)  27,359,383,552 bytes free\n"
     ]
    }
   ],
   "source": [
    "% ls \"model\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'build_input_shape': [None, 784],\n",
      " 'layers': [{'class_name': 'Dense',\n",
      "             'config': {'activation': 'softmax',\n",
      "                        'activity_regularizer': None,\n",
      "                        'bias_constraint': None,\n",
      "                        'bias_initializer': {'class_name': 'Zeros',\n",
      "                                             'config': {}},\n",
      "                        'bias_regularizer': None,\n",
      "                        'kernel_constraint': None,\n",
      "                        'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                                               'config': {'distribution': 'uniform',\n",
      "                                                          'mode': 'fan_avg',\n",
      "                                                          'scale': 1.0,\n",
      "                                                          'seed': None}},\n",
      "                        'kernel_regularizer': None,\n",
      "                        'name': 'dense_2',\n",
      "                        'trainable': True,\n",
      "                        'units': 10,\n",
      "                        'use_bias': True}}],\n",
      " 'name': 'sequential_2'}\n"
     ]
    }
   ],
   "source": [
    "filename = '20190818 172933.keras'\n",
    "filepath = os.path.join('model',filename)\n",
    "model = keras.models.load_model(filepath)\n",
    "print(model.summary())\n",
    "pprint.pprint(model.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import gzip\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte.gz' % kind)\n",
    "        \n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        lbpath.read(8)\n",
    "        buffer = lbpath.read()\n",
    "        labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        imgpath.read(16)\n",
    "        buffer = imgpath.read()\n",
    "        images = np.frombuffer(buffer, \n",
    "                               dtype=np.uint8).reshape(\n",
    "            len(labels), 784).astype(np.float64)\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_mnist('data/', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))\n",
    "y_test_orig = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randrange(X_test.shape[0])\n",
    "X = X_test[i]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEHYAEhB2ABIQdgASEHYAEhB2ABI8f/Ayi/ETSpJswAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = X.reshape(28, 28)\n",
    "plt.imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/mnist_all.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "[[1.6127527e-05 7.8669615e-14 9.9936861e-01 6.0537120e-04 5.6937655e-08\n",
      "  9.4129909e-06 1.2634236e-08 6.8006303e-14 5.5854832e-07 7.0467564e-12]]\n",
      "1/1 [==============================] - 0s 1ms/step\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "#expand dims needed because model.predict expects a a 2D array of shape (num_instances, features)\n",
    "print(model.predict(np.expand_dims(X, axis=0), verbose=1))\n",
    "#expand dims needed because model.predict expects a a 2D array of shape (num_instances, features)\n",
    "print(model.predict_classes(np.expand_dims(X, axis=0), verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the prediction made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 784 values (pixels) in each image\n",
      "The values range from 0.0 to 255.0. 0 = White, 255 = Blank.\n",
      "The values are divided by 255 to remap them to between 0 and 1\n",
      "The new values range from 0.0 to 1.0. 0 = White, 1 = Blank.\n"
     ]
    }
   ],
   "source": [
    "X = X_test[i].copy()\n",
    "\n",
    "print(f'There are {len(X)} values (pixels) in each image')\n",
    "print(f'The values range from {min(X)} to {max(X)}. 0 = White, 255 = Blank.')\n",
    "print(f'The values are divided by 255 to remap them to between 0 and 1')\n",
    "X /= 255\n",
    "print(f'The new values range from {min(X)} to {max(X)}. 0 = White, 1 = Blank.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 layers in the model\n",
      "The layer configuration is:\n",
      "{'activation': 'softmax',\n",
      " 'activity_regularizer': None,\n",
      " 'bias_constraint': None,\n",
      " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      " 'bias_regularizer': None,\n",
      " 'kernel_constraint': None,\n",
      " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                        'config': {'distribution': 'uniform',\n",
      "                                   'mode': 'fan_avg',\n",
      "                                   'scale': 1.0,\n",
      "                                   'seed': None}},\n",
      " 'kernel_regularizer': None,\n",
      " 'name': 'dense_2',\n",
      " 'trainable': True,\n",
      " 'units': 10,\n",
      " 'use_bias': True}\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(model.layers)} layers in the model')\n",
    "print(f'The layer configuration is:')\n",
    "layer = model.layers[0]\n",
    "pprint.pprint(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input for the layer is type <class 'tensorflow.python.framework.ops.Tensor'>. The input shape is (None, 784)\n",
      "The output for the layer is type <class 'tensorflow.python.framework.ops.Tensor'>. The output shape is (None, 10)\n",
      "The shape of the layer weights is (784, 10). There are 7840 weights\n",
      "The share of the layer biases is (10,) biases\n"
     ]
    }
   ],
   "source": [
    "print(f'The input for the layer is type {type(layer.input)}. The input shape is {layer.input_shape}')\n",
    "print(f'The output for the layer is type {type(layer.output)}. The output shape is {layer.output_shape}')\n",
    "\n",
    "\n",
    "print(f'The shape of the layer weights is {layer.get_weights()[0].shape}. There are {np.product(layer.get_weights()[0].shape)} weights')\n",
    "print(f'The share of the layer biases is {layer.get_weights()[1].shape} biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  i:o\n",
      "The weight of the 0:0 connection is -0.0324\n",
      "The weight of the 0:1 connection is -0.00806\n",
      "The weight of the 0:2 connection is -0.0533\n",
      "The weight of the 0:3 connection is 0.0273\n",
      "The weight of the 0:4 connection is 0.000802\n",
      "The weight of the 0:5 connection is -0.00952\n",
      "The weight of the 0:6 connection is -0.0407\n",
      "The weight of the 0:7 connection is 0.0476\n",
      "The weight of the 0:8 connection is -0.0791\n",
      "The weight of the 0:9 connection is 0.0578\n",
      "\n",
      "                  i:o\n",
      "The weight of the 1:0 connection is -0.0342\n",
      "The weight of the 1:1 connection is -0.0435\n",
      "The weight of the 1:2 connection is 0.078\n",
      "The weight of the 1:3 connection is -0.0283\n",
      "The weight of the 1:4 connection is 0.0351\n",
      "The weight of the 1:5 connection is 0.0466\n",
      "The weight of the 1:6 connection is 0.0455\n",
      "The weight of the 1:7 connection is -0.00786\n",
      "The weight of the 1:8 connection is 0.0359\n",
      "The weight of the 1:9 connection is 0.0633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getConnectionWeight(layer,i_input,i_output):\n",
    "    return layer.get_weights()[0][i_input][i_output]\n",
    "\n",
    "i_input = 0\n",
    "i_output = 0\n",
    "\n",
    "for i_input in range(2):\n",
    "    print(f'                  i:o')\n",
    "    for i_output in range(10):\n",
    "        #print(f'The weight of the {i_input}:{i_output} connection is {layer.get_weights()[0][i_input][i_output]:{3}.{3}}')\n",
    "        print(f'The weight of the {i_input}:{i_output} connection is {getConnectionWeight(layer,i_input,i_output):{3}.{3}}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of the 0 output connection is -0.367\n",
      "The weight of the 1 output connection is 0.399\n",
      "The weight of the 2 output connection is 0.0375\n",
      "The weight of the 3 output connection is -0.222\n",
      "The weight of the 4 output connection is 0.024\n",
      "The weight of the 5 output connection is 0.712\n",
      "The weight of the 6 output connection is -0.151\n",
      "The weight of the 7 output connection is 0.412\n",
      "The weight of the 8 output connection is -0.856\n",
      "The weight of the 9 output connection is -0.172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getConnectionBias(layer,i_output):\n",
    "    return layer.get_weights()[1][i_output]\n",
    "\n",
    "for i_output in range(len(layer.get_weights()[1])):\n",
    "    #print(f'The weight of the {i_input}:{i_output} connection is {layer.get_weights()[0][i_input][i_output]:{3}.{3}}')\n",
    "    print(f'The weight of the {i_output} output connection is {getConnectionBias(layer,i_output):{3}.{3}}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the Output Value of the top output (0), We take each value of X, multiply it by the weight, add them up, add the bias, then...?\n"
     ]
    }
   ],
   "source": [
    "print(f'To calculate the Output Value of the top output (0), We take each value of X'\n",
    "      f', multiply it by the weight, add them up, add the bias, then...?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output index: 0\n",
      "-0.032 x 0.0 = -0.0\n",
      "-0.034 x 0.0 = -0.0\n",
      "0.021 x 0.0 = 0.0\n",
      "0.015 x 0.0 = 0.0\n",
      "0.074 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -15.33399154636644\n",
      "\n",
      "The bias is -0.3670988082885742\n",
      " -15.33399154636644+-0.3670988082885742 = -15.701090354655014 \n",
      "\n",
      "Output index: 1\n",
      "-0.0081 x 0.0 = -0.0\n",
      "-0.043 x 0.0 = -0.0\n",
      "-0.085 x 0.0 = -0.0\n",
      "0.043 x 0.0 = 0.0\n",
      "-0.031 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -35.23889922228658\n",
      "\n",
      "The bias is 0.3992721438407898\n",
      " -35.23889922228658+0.3992721438407898 = -34.83962707844579 \n",
      "\n",
      "Output index: 2\n",
      "-0.053 x 0.0 = -0.0\n",
      "0.078 x 0.0 = 0.0\n",
      "0.0094 x 0.0 = 0.0\n",
      "-0.049 x 0.0 = -0.0\n",
      "-0.03 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -4.704249619194035\n",
      "\n",
      "The bias is 0.03751373663544655\n",
      " -4.704249619194035+0.03751373663544655 = -4.666735882558588 \n",
      "\n",
      "Output index: 3\n",
      "0.027 x 0.0 = 0.0\n",
      "-0.028 x 0.0 = -0.0\n",
      "-0.004 x 0.0 = -0.0\n",
      "-0.026 x 0.0 = -0.0\n",
      "-0.006 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -11.85360273033329\n",
      "\n",
      "The bias is -0.22217315435409546\n",
      " -11.85360273033329+-0.22217315435409546 = -12.075775884687385 \n",
      "\n",
      "Output index: 4\n",
      "0.0008 x 0.0 = 0.0\n",
      "0.035 x 0.0 = 0.0\n",
      "0.031 x 0.0 = 0.0\n",
      "0.051 x 0.0 = 0.0\n",
      "0.081 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -21.371389413637797\n",
      "\n",
      "The bias is 0.023973498493433\n",
      " -21.371389413637797+0.023973498493433 = -21.347415915144364 \n",
      "\n",
      "Output index: 5\n",
      "-0.0095 x 0.0 = -0.0\n",
      "0.047 x 0.0 = 0.0\n",
      "-0.068 x 0.0 = -0.0\n",
      "0.044 x 0.0 = 0.0\n",
      "-0.085 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -16.951140503628245\n",
      "\n",
      "The bias is 0.7116121649742126\n",
      " -16.951140503628245+0.7116121649742126 = -16.239528338654033 \n",
      "\n",
      "Output index: 6\n",
      "-0.041 x 0.0 = -0.0\n",
      "0.045 x 0.0 = 0.0\n",
      "-0.017 x 0.0 = -0.0\n",
      "0.046 x 0.0 = 0.0\n",
      "0.075 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -22.702239004158255\n",
      "\n",
      "The bias is -0.15072602033615112\n",
      " -22.702239004158255+-0.15072602033615112 = -22.852965024494406 \n",
      "\n",
      "Output index: 7\n",
      "0.048 x 0.0 = 0.0\n",
      "-0.0079 x 0.0 = -0.0\n",
      "0.066 x 0.0 = 0.0\n",
      "0.029 x 0.0 = 0.0\n",
      "-0.0091 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -35.39690416340889\n",
      "\n",
      "The bias is 0.41161996126174927\n",
      " -35.39690416340889+0.41161996126174927 = -34.98528420214714 \n",
      "\n",
      "Output index: 8\n",
      "-0.079 x 0.0 = -0.0\n",
      "0.036 x 0.0 = 0.0\n",
      "0.066 x 0.0 = 0.0\n",
      "-0.077 x 0.0 = -0.0\n",
      "-0.0099 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -18.208074222931952\n",
      "\n",
      "The bias is -0.8559573888778687\n",
      " -18.208074222931952+-0.8559573888778687 = -19.06403161180982 \n",
      "\n",
      "Output index: 9\n",
      "0.058 x 0.0 = 0.0\n",
      "0.063 x 0.0 = 0.0\n",
      "0.02 x 0.0 = 0.0\n",
      "-0.05 x 0.0 = -0.0\n",
      "-0.072 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -30.172423617942634\n",
      "\n",
      "The bias is -0.1721409559249878\n",
      " -30.172423617942634+-0.1721409559249878 = -30.344564573867622 \n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for i_output in range(10):\n",
    "    print()\n",
    "    print(f'Output index: {i_output}')\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    for i_input in range(len(X)):\n",
    "        if i_input < 5:\n",
    "            print(f'{getConnectionWeight(layer,i_input,i_output):{2}.{2}} x {X[i_input]:{2}.{2}} = '\n",
    "                  f'{getConnectionWeight(layer,i_input,i_output)*X[i_input]:{3}.{3}}')\n",
    "        if i_input == 5:\n",
    "            print('etc...')\n",
    "        sum += getConnectionWeight(layer,i_input,i_output)*X[i_input]\n",
    "\n",
    "    print (f'The summation is {sum}')\n",
    "    print ()\n",
    "    print (f'The bias is {getConnectionBias(layer,i_output)}')\n",
    "    print (f' {sum}+{getConnectionBias(layer,i_output)} = {sum+getConnectionBias(layer,i_output)} ')\n",
    "    \n",
    "    output.append(sum+getConnectionBias(layer,i_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before applying softmax function\n",
      "0: -15.701090354655014\n",
      "1: -34.83962707844579\n",
      "2: -4.666735882558588\n",
      "3: -12.075775884687385\n",
      "4: -21.347415915144364\n",
      "5: -16.239528338654033\n",
      "6: -22.852965024494406\n",
      "7: -34.98528420214714\n",
      "8: -19.06403161180982\n",
      "9: -30.344564573867622\n"
     ]
    }
   ],
   "source": [
    "print (f'Before applying softmax function')\n",
    "for i in range(len(output)):\n",
    "    print(f'{i}: {output[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying softmax function\n",
      "0: 1.6127475147675992e-05\n",
      "1: 7.866933707014053e-14\n",
      "2: 0.999368462068821\n",
      "3: 0.000605369380739688\n",
      "4: 5.6937493845352736e-08\n",
      "5: 9.41294965817269e-06\n",
      "6: 1.2634168855786973e-08\n",
      "7: 6.80060272914356e-14\n",
      "8: 5.585467773115596e-07\n",
      "9: 7.046708914451028e-12\n"
     ]
    }
   ],
   "source": [
    "print (f'After applying softmax function')\n",
    "from scipy.special import softmax\n",
    "m = softmax(output)\n",
    "for i in range(len(m)):\n",
    "    print(f'{i}: {m[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step\n",
      "Keras model.predict function equivelent\n",
      "0: 1.612752748769708e-05\n",
      "1: 7.866961476785811e-14\n",
      "2: 0.9993686079978943\n",
      "3: 0.0006053711986169219\n",
      "4: 5.69376545911382e-08\n",
      "5: 9.412990948476363e-06\n",
      "6: 1.2634235879716016e-08\n",
      "7: 6.800630344234657e-14\n",
      "8: 5.585483222603216e-07\n",
      "9: 7.046756407558252e-12\n"
     ]
    }
   ],
   "source": [
    "keras_output = model.predict(np.expand_dims(X, axis=0), verbose=1)[0]\n",
    "print (f'Keras model.predict function equivelent')\n",
    "for i in range(len(keras_output)):\n",
    "    print(f'{i}: {keras_output[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Can this be sped up using matrix multiplication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-15.33399155, -35.23889922,  -4.70424962, -11.85360273,\n",
       "       -21.37138941, -16.9511405 , -22.702239  , -35.39690416,\n",
       "       -18.20807422, -30.17242362])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,layer.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: -15.701090354655015\n",
      "1: -34.8396270784458\n",
      "2: -4.6667358825585845\n",
      "3: -12.0757758846874\n",
      "4: -21.347415915144346\n",
      "5: -16.23952833865404\n",
      "6: -22.85296502449441\n",
      "7: -34.98528420214711\n",
      "8: -19.064031611809824\n",
      "9: -30.344564573867608\n",
      "\n",
      "0: 1.6127475147675904e-05\n",
      "1: 7.866933707013942e-14\n",
      "2: 0.999368462068821\n",
      "3: 0.0006053693807396761\n",
      "4: 5.693749384535354e-08\n",
      "5: 9.412949658172588e-06\n",
      "6: 1.2634168855786884e-08\n",
      "7: 6.800602729143754e-14\n",
      "8: 5.585467773115556e-07\n",
      "9: 7.046708914451128e-12\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "prediction = np.dot(X,layer.get_weights()[0])+layer.get_weights()[1]\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    print(f'{i}: {prediction[i]}')\n",
    "    \n",
    "print()    \n",
    "prediction = softmax(np.dot(X,layer.get_weights()[0])+layer.get_weights()[1])\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    print(f'{i}: {prediction[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
