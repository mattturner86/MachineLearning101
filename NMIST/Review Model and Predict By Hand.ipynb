{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattt_000\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is D4F8-2F03\n",
      "\n",
      " Directory of C:\\Users\\mattt_000\\Documents\\MachineLearning101\\MachineLearning101\\NMIST\\model\n",
      "\n",
      "18/08/2019  17:29    <DIR>          .\n",
      "18/08/2019  17:29    <DIR>          ..\n",
      "18/08/2019  11:08            78,480 20190818 110820.keras\n",
      "18/08/2019  11:21            78,480 20190818 112143.keras\n",
      "18/08/2019  17:29            78,480 20190818 172933.keras\n",
      "               3 File(s)        235,440 bytes\n",
      "               2 Dir(s)  30,310,965,248 bytes free\n"
     ]
    }
   ],
   "source": [
    "% ls \"model\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mattt_000\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\mattt_000\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "{'build_input_shape': [None, 784],\n",
      " 'layers': [{'class_name': 'Dense',\n",
      "             'config': {'activation': 'softmax',\n",
      "                        'activity_regularizer': None,\n",
      "                        'bias_constraint': None,\n",
      "                        'bias_initializer': {'class_name': 'Zeros',\n",
      "                                             'config': {}},\n",
      "                        'bias_regularizer': None,\n",
      "                        'kernel_constraint': None,\n",
      "                        'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                                               'config': {'distribution': 'uniform',\n",
      "                                                          'mode': 'fan_avg',\n",
      "                                                          'scale': 1.0,\n",
      "                                                          'seed': None}},\n",
      "                        'kernel_regularizer': None,\n",
      "                        'name': 'dense_2',\n",
      "                        'trainable': True,\n",
      "                        'units': 10,\n",
      "                        'use_bias': True}}],\n",
      " 'name': 'sequential_2'}\n"
     ]
    }
   ],
   "source": [
    "filename = '20190818 172933.keras'\n",
    "filepath = os.path.join('model',filename)\n",
    "model = keras.models.load_model(filepath)\n",
    "print(model.summary())\n",
    "pprint.pprint(model.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import gzip\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte.gz' % kind)\n",
    "        \n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        lbpath.read(8)\n",
    "        buffer = lbpath.read()\n",
    "        labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        imgpath.read(16)\n",
    "        buffer = imgpath.read()\n",
    "        images = np.frombuffer(buffer, \n",
    "                               dtype=np.uint8).reshape(\n",
    "            len(labels), 784).astype(np.float64)\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_mnist('data/', kind='t10k')\n",
    "print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))\n",
    "y_test_orig = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "i = random.randrange(X_test.shape[0])\n",
    "X = X_test[i]/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARsAAAEYCAYAAABsuVKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2ABI8XdgXmw3Kavf2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = X.reshape(28, 28)\n",
    "plt.imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/mnist_all.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[[4.1263146e-11 9.9888426e-01 2.1175932e-05 9.8319387e-04 3.0028716e-07\n",
      "  3.8145424e-06 5.8443788e-06 1.3929596e-06 7.7012046e-05 2.2876451e-05]]\n",
      "1/1 [==============================] - 0s 3ms/step\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#expand dims needed because model.predict expects a a 2D array of shape (num_instances, features)\n",
    "print(model.predict(np.expand_dims(X, axis=0), verbose=1))\n",
    "#expand dims needed because model.predict expects a a 2D array of shape (num_instances, features)\n",
    "print(model.predict_classes(np.expand_dims(X, axis=0), verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the prediction made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 784 values (pixels) in each image\n",
      "The values range from 0.0 to 255.0. 0 = White, 255 = Blank.\n",
      "The values are divided by 255 to remap them to between 0 and 1\n",
      "The new values range from 0.0 to 1.0. 0 = White, 1 = Blank.\n"
     ]
    }
   ],
   "source": [
    "X = X_test[i].copy()\n",
    "\n",
    "print(f'There are {len(X)} values (pixels) in each image')\n",
    "print(f'The values range from {min(X)} to {max(X)}. 0 = White, 255 = Blank.')\n",
    "print(f'The values are divided by 255 to remap them to between 0 and 1')\n",
    "X /= 255\n",
    "print(f'The new values range from {min(X)} to {max(X)}. 0 = White, 1 = Blank.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 layers in the model\n",
      "The layer configuration is:\n",
      "{'activation': 'softmax',\n",
      " 'activity_regularizer': None,\n",
      " 'bias_constraint': None,\n",
      " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
      " 'bias_regularizer': None,\n",
      " 'kernel_constraint': None,\n",
      " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                        'config': {'distribution': 'uniform',\n",
      "                                   'mode': 'fan_avg',\n",
      "                                   'scale': 1.0,\n",
      "                                   'seed': None}},\n",
      " 'kernel_regularizer': None,\n",
      " 'name': 'dense_2',\n",
      " 'trainable': True,\n",
      " 'units': 10,\n",
      " 'use_bias': True}\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(model.layers)} layers in the model')\n",
    "print(f'The layer configuration is:')\n",
    "layer = model.layers[0]\n",
    "pprint.pprint(layer.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input for the layer is type <class 'tensorflow.python.framework.ops.Tensor'>. The input shape is (None, 784)\n",
      "The output for the layer is type <class 'tensorflow.python.framework.ops.Tensor'>. The output shape is (None, 10)\n",
      "The shape of the layer weights is (784, 10). There are 7840 weights\n",
      "The share of the layer biases is (10,) biases\n"
     ]
    }
   ],
   "source": [
    "print(f'The input for the layer is type {type(layer.input)}. The input shape is {layer.input_shape}')\n",
    "print(f'The output for the layer is type {type(layer.output)}. The output shape is {layer.output_shape}')\n",
    "\n",
    "\n",
    "print(f'The shape of the layer weights is {layer.get_weights()[0].shape}. There are {np.product(layer.get_weights()[0].shape)} weights')\n",
    "print(f'The share of the layer biases is {layer.get_weights()[1].shape} biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  i:o\n",
      "The weight of the 0:0 connection is -0.0324\n",
      "The weight of the 0:1 connection is -0.00806\n",
      "The weight of the 0:2 connection is -0.0533\n",
      "The weight of the 0:3 connection is 0.0273\n",
      "The weight of the 0:4 connection is 0.000802\n",
      "The weight of the 0:5 connection is -0.00952\n",
      "The weight of the 0:6 connection is -0.0407\n",
      "The weight of the 0:7 connection is 0.0476\n",
      "The weight of the 0:8 connection is -0.0791\n",
      "The weight of the 0:9 connection is 0.0578\n",
      "\n",
      "                  i:o\n",
      "The weight of the 1:0 connection is -0.0342\n",
      "The weight of the 1:1 connection is -0.0435\n",
      "The weight of the 1:2 connection is 0.078\n",
      "The weight of the 1:3 connection is -0.0283\n",
      "The weight of the 1:4 connection is 0.0351\n",
      "The weight of the 1:5 connection is 0.0466\n",
      "The weight of the 1:6 connection is 0.0455\n",
      "The weight of the 1:7 connection is -0.00786\n",
      "The weight of the 1:8 connection is 0.0359\n",
      "The weight of the 1:9 connection is 0.0633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getConnectionWeight(layer,i_input,i_output):\n",
    "    return layer.get_weights()[0][i_input][i_output]\n",
    "\n",
    "i_input = 0\n",
    "i_output = 0\n",
    "\n",
    "for i_input in range(2):\n",
    "    print(f'                  i:o')\n",
    "    for i_output in range(10):\n",
    "        #print(f'The weight of the {i_input}:{i_output} connection is {layer.get_weights()[0][i_input][i_output]:{3}.{3}}')\n",
    "        print(f'The weight of the {i_input}:{i_output} connection is {getConnectionWeight(layer,i_input,i_output):{3}.{3}}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of the 0 output connection is -0.367\n",
      "The weight of the 1 output connection is 0.399\n",
      "The weight of the 2 output connection is 0.0375\n",
      "The weight of the 3 output connection is -0.222\n",
      "The weight of the 4 output connection is 0.024\n",
      "The weight of the 5 output connection is 0.712\n",
      "The weight of the 6 output connection is -0.151\n",
      "The weight of the 7 output connection is 0.412\n",
      "The weight of the 8 output connection is -0.856\n",
      "The weight of the 9 output connection is -0.172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getConnectionBias(layer,i_output):\n",
    "    return layer.get_weights()[1][i_output]\n",
    "\n",
    "for i_output in range(len(layer.get_weights()[1])):\n",
    "    #print(f'The weight of the {i_input}:{i_output} connection is {layer.get_weights()[0][i_input][i_output]:{3}.{3}}')\n",
    "    print(f'The weight of the {i_output} output connection is {getConnectionBias(layer,i_output):{3}.{3}}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To calculate the Output Value of the top output (0), We take each value of X, multiply it by the weight, add them up, add the bias, then...?\n"
     ]
    }
   ],
   "source": [
    "print(f'To calculate the Output Value of the top output (0), We take each value of X'\n",
    "      f', multiply it by the weight, add them up, add the bias, then...?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output index: 0\n",
      "-0.032 x 0.0 = -0.0\n",
      "-0.034 x 0.0 = -0.0\n",
      "0.021 x 0.0 = 0.0\n",
      "0.015 x 0.0 = 0.0\n",
      "0.074 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -18.040252579138713\n",
      "\n",
      "The bias is -0.3670988082885742\n",
      " -18.040252579138713+-0.3670988082885742 = -18.407351387427287 \n",
      "\n",
      "Output index: 1\n",
      "-0.0081 x 0.0 = -0.0\n",
      "-0.043 x 0.0 = -0.0\n",
      "-0.085 x 0.0 = -0.0\n",
      "0.043 x 0.0 = 0.0\n",
      "-0.031 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is 5.1033100463011705\n",
      "\n",
      "The bias is 0.3992721438407898\n",
      " 5.1033100463011705+0.3992721438407898 = 5.50258219014196 \n",
      "\n",
      "Output index: 2\n",
      "-0.053 x 0.0 = -0.0\n",
      "0.078 x 0.0 = 0.0\n",
      "0.0094 x 0.0 = 0.0\n",
      "-0.049 x 0.0 = -0.0\n",
      "-0.03 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -5.296460820005879\n",
      "\n",
      "The bias is 0.03751373663544655\n",
      " -5.296460820005879+0.03751373663544655 = -5.258947083370432 \n",
      "\n",
      "Output index: 3\n",
      "0.027 x 0.0 = 0.0\n",
      "-0.028 x 0.0 = -0.0\n",
      "-0.004 x 0.0 = -0.0\n",
      "-0.026 x 0.0 = -0.0\n",
      "-0.006 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -1.198832436975128\n",
      "\n",
      "The bias is -0.22217315435409546\n",
      " -1.198832436975128+-0.22217315435409546 = -1.4210055913292234 \n",
      "\n",
      "Output index: 4\n",
      "0.0008 x 0.0 = 0.0\n",
      "0.035 x 0.0 = 0.0\n",
      "0.031 x 0.0 = 0.0\n",
      "0.051 x 0.0 = 0.0\n",
      "0.081 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -9.538802043447161\n",
      "\n",
      "The bias is 0.023973498493433\n",
      " -9.538802043447161+0.023973498493433 = -9.514828544953728 \n",
      "\n",
      "Output index: 5\n",
      "-0.0095 x 0.0 = -0.0\n",
      "0.047 x 0.0 = 0.0\n",
      "-0.068 x 0.0 = -0.0\n",
      "0.044 x 0.0 = 0.0\n",
      "-0.085 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -7.684603294180524\n",
      "\n",
      "The bias is 0.7116121649742126\n",
      " -7.684603294180524+0.7116121649742126 = -6.972991129206311 \n",
      "\n",
      "Output index: 6\n",
      "-0.041 x 0.0 = -0.0\n",
      "0.045 x 0.0 = 0.0\n",
      "-0.017 x 0.0 = -0.0\n",
      "0.046 x 0.0 = 0.0\n",
      "0.075 x 0.0 = 0.0\n",
      "etc...\n",
      "The summation is -6.395606525492504\n",
      "\n",
      "The bias is -0.15072602033615112\n",
      " -6.395606525492504+-0.15072602033615112 = -6.546332545828655 \n",
      "\n",
      "Output index: 7\n",
      "0.048 x 0.0 = 0.0\n",
      "-0.0079 x 0.0 = -0.0\n",
      "0.066 x 0.0 = 0.0\n",
      "0.029 x 0.0 = 0.0\n",
      "-0.0091 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -8.392002176154199\n",
      "\n",
      "The bias is 0.41161996126174927\n",
      " -8.392002176154199+0.41161996126174927 = -7.980382214892449 \n",
      "\n",
      "Output index: 8\n",
      "-0.079 x 0.0 = -0.0\n",
      "0.036 x 0.0 = 0.0\n",
      "0.066 x 0.0 = 0.0\n",
      "-0.077 x 0.0 = -0.0\n",
      "-0.0099 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -3.1118930790500317\n",
      "\n",
      "The bias is -0.8559573888778687\n",
      " -3.1118930790500317+-0.8559573888778687 = -3.9678504679279003 \n",
      "\n",
      "Output index: 9\n",
      "0.058 x 0.0 = 0.0\n",
      "0.063 x 0.0 = 0.0\n",
      "0.02 x 0.0 = 0.0\n",
      "-0.05 x 0.0 = -0.0\n",
      "-0.072 x 0.0 = -0.0\n",
      "etc...\n",
      "The summation is -5.009562474021725\n",
      "\n",
      "The bias is -0.1721409559249878\n",
      " -5.009562474021725+-0.1721409559249878 = -5.181703429946713 \n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for i_output in range(10):\n",
    "    print()\n",
    "    print(f'Output index: {i_output}')\n",
    "\n",
    "    sum = 0\n",
    "\n",
    "    for i_input in range(len(X)):\n",
    "        if i_input < 5:\n",
    "            print(f'{getConnectionWeight(layer,i_input,i_output):{2}.{2}} x {X[i_input]:{2}.{2}} = '\n",
    "                  f'{getConnectionWeight(layer,i_input,i_output)*X[i_input]:{3}.{3}}')\n",
    "        if i_input == 5:\n",
    "            print('etc...')\n",
    "        sum += getConnectionWeight(layer,i_input,i_output)*X[i_input]\n",
    "\n",
    "    print (f'The summation is {sum}')\n",
    "    print ()\n",
    "    print (f'The bias is {getConnectionBias(layer,i_output)}')\n",
    "    print (f' {sum}+{getConnectionBias(layer,i_output)} = {sum+getConnectionBias(layer,i_output)} ')\n",
    "    \n",
    "    output.append(sum+getConnectionBias(layer,i_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before applying softmax function\n",
      "0: -18.407351387427287\n",
      "1: 5.50258219014196\n",
      "2: -5.258947083370432\n",
      "3: -1.4210055913292234\n",
      "4: -9.514828544953728\n",
      "5: -6.972991129206311\n",
      "6: -6.546332545828655\n",
      "7: -7.980382214892449\n",
      "8: -3.9678504679279003\n",
      "9: -5.181703429946713\n"
     ]
    }
   ],
   "source": [
    "print (f'Before applying softmax function')\n",
    "for i in range(len(output)):\n",
    "    print(f'{i}: {output[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying softmax function\n",
      "0: 4.126321003910641e-11\n",
      "1: 0.9988843892835515\n",
      "2: 2.1175927706398372e-05\n",
      "3: 0.0009831940858416551\n",
      "4: 3.0028705536346073e-07\n",
      "5: 3.814543525961272e-06\n",
      "6: 5.8443745810330685e-06\n",
      "7: 1.3929585235673376e-06\n",
      "8: 7.701203177161729e-05\n",
      "9: 2.2876466179867054e-05\n"
     ]
    }
   ],
   "source": [
    "print (f'After applying softmax function')\n",
    "from scipy.special import softmax\n",
    "m = softmax(output)\n",
    "for i in range(len(m)):\n",
    "    print(f'{i}: {m[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 995us/step\n",
      "0: 4.1263145678094304e-11\n",
      "1: 0.9988842606544495\n",
      "2: 2.1175932488404214e-05\n",
      "3: 0.0009831938659772277\n",
      "4: 3.0028715514163196e-07\n",
      "5: 3.814542424152023e-06\n",
      "6: 5.84437884754152e-06\n",
      "7: 1.392959575241548e-06\n",
      "8: 7.701204594923183e-05\n",
      "9: 2.287645111209713e-05\n"
     ]
    }
   ],
   "source": [
    "keras_output = model.predict(np.expand_dims(X, axis=0), verbose=1)[0]\n",
    "\n",
    "for i in range(len(keras_output)):\n",
    "    print(f'{i}: {keras_output[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
